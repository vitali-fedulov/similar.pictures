<!-- Copyright by Vitali Fedulov (fedulov.vitali@gmail.com) 2015-2021 -->

<!DOCTYPE html>
<html lang="en">

<head>
  <title>Algorithm for hashing float vectors</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="icon" type="image/png" href="images/favicon.png">
  <link rel="stylesheet" type="text/css" href="css/index.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto">
</head>




<body>

  <!-- Header  -->
  <div class="header">
      <a href = "index.html" class="logo"><h1>Similar<span class="logo-dot">.</span>Pictures</h1></a>
      <h4 class="logo-statement">Find near duplicates on your computer</h4>
  </div>
  
  <div class="nav">
      <!-- Set manually class "active" for corresponding nav-tab. -->
      <div class="nav-tab"><a href="index.html">Home</a></div>
      <div class="nav-tab"><a href="duplicate-image-search-example.html">Demo</a></div>
      <div class="nav-tab active"><a href="research.html">Research</a></div>
      <div class="nav-tab"><a href="tools.html">Tools</a></div>
      <div class="nav-tab"><a href="about.html">About</a></div>
      <div class="line"></div> <!-- Gray line placeholder. Should stay here. -->
  </div>


  <!-- Blog organization:
    1. Home page navigation links to the latest blog-[date].html file. The pages must never
       change file name/address, so if linked by other sites they stay constant.
    2. Each blog page will later have a list of all articles linked by html injection,
       e.g. secondary navigation menu. Place in upper part of the blog as TOC.
  -->

  <!-- Contents -->

  <p class="published">fedulov.vitali@gmail.com, <time datetime="2021-12-07">7 Dec. 2021</time></p>
  <h3 id="2021-12-07">Float N-dimensional vector hashing</h3>  <!-- Id used for URL anchors.-->
    

  <p>The scope of the article is fast approximate vector comparison in N-dimensional spaces. A method to hash float vectors is presented. The method has been developed in the context of large scale image comparison.</p>

  <p>Hash tables allow fast search. But not every value is suitable for hashing. For example how could you hash a person's height? There would be a near infinite number of hashes to find equal ones for comparison. Hashing in higher dimensions is even more challenging.</p>

  <p>Here I demonstrate a method to hash numerical Float values and other values of high density, such as Int, by using binary bucket trees. In the method each component of a vector is projected into 1 or 2 buckets per dimension. Bucket numbers form hashes by appending them sequentially dimension by dimension.</p>

  <p>In general, in each dimension, buckets can have variable widths. For example, if values come from interval (-Infinity, +Infinity), we could split this infinite space into finite K buckets with some kind of distribution reflecting the data (bell-curve or other). It might be good to analyze each dimension of your vectors to get the distribution curve, and split each axis so that each bucket contains approximately the same number of values.</p>

  <p>Value distribution is important, but in the method below I assume that buckets have equal widths and that we consider a fixed interval of float values [min, max] per dimension. For example, (0.0, 300.0) cm is a safe interval to measure humans, and 10 cm could be the bucket width.</p>

  <p>To be able to hash/compare a float value, we need its bucket number. But it is not sufficient to check that a float value falls into a specific bucket. What if it falls exactly at a bucket split point? Or one value falls near the split on one side, and another similar value falls on the other side? Besides, those values typically contain measurements errors. Therefore we will introduce an uncertainty neighbourhood of a value: (x-ɛ, x+ɛ).</p>

  <p>Let's start with 1-dimensional vector:</p>

  <figure class="blog-img-1">
    <img src="images/21.12.07-buckets-01.gif" alt="1-dimensional buckets">
    <figcaption>Bucket number of the left value is somewhat uncertain</figcaption>
  </figure>



  <p>If a float value falls near the center of a bucket, we would feel safe to allocate a single bucket for this value. But if the value finds itself near the bucket border, as in the picture above, the nearby bucket should also be included. By introducing a neighbourhood interval around the float value, we will get more than one bucket corresponding to such value:</p>

  <figure class="blog-img-1">
    <img src="images/21.12.07-buckets-02.gif" alt="1-dimensional buckets with uncertainty interval">
    <figcaption>Introducing the uncertainty interval of different sizes</figcaption>
  </figure>


  <p>In the 1st case above 2 buckets are "activated" by the uncertainty interval. Therefore 2 bucket numbers will be necessary to represent one value.</p>

  <p>In the 2nd case, the epsilon interval covers many buckets to represent one float value. This is impractical. An ideal bucket width must be larger than 2ɛ. Then a float value will fall into maximum 2 buckets. There is no "free lunch" to have all values in 1 bucket only - some will luckily do, but some will require 2 buckets. This is the price to be able to compare values, as explained above.</p>


  <p>From now on we assume that bucket width is larger than 2ɛ.</p>

  <p>As showed above, the uncertainty requires 2 buckets "reserved" in 1-dimensional space. If bucket width is much larger than ɛ, there will be few values with their uncertainty intervals overlaying 2 buckets, because probability of a value to be near a bucket border will be smaller. In such configuration most values will require only 1 bucket number to be correctly represented.</p>
  
  <p>Now, let's consider higher dimensional space.</p>
  
  <figure class="blog-img-1">
    <img src="images/21.12.07-buckets-03.gif" alt="2-dimensional hypercubes">
    <figcaption>Buckets for dimension x and y, their uncertainty intervals,<br>and corresponding 2-dimensional hypercubes</figcaption>
  </figure>

  
  <p>In N-space buckets are defined the same way as for one dimension, that is in relation to bucket borders. In 2 dimensions (figure above) buckets become vertical and horizontal stripes (the space between two parallel black lines). Corresponding uncertainty regions are also stripes (pink regions above). In 3D buckets become slices, and so on for higher dimensions.</p>

  <p>Bucket intersections form hypercubes, which correspond to the final hashes. The hashes (hypercubes) will be ultimately used to compare float vector values.</p>
  
  <p>As showed before, assuming that the bucket width is larger than 2ɛ, for one dimension we need 1-2 buckets. For 2D we will need 2-4 buckets (at least 1 and maximum 2 for each dimension). In 3D we can get 3-8 buckets. Those 8 buckets are total buckets in all the 3 dimensions.</p>
    
  <p>Below is shown the smallest number of buckets necessary in 2D case.</p>

  <figure class="blog-img-1">
    <img src="images/21.12.07-buckets-04.gif" alt="2-dimensional hypercubes">
    <figcaption>The case of minimal number of buckets necessary in 2D</figcaption>
  </figure>
  
  <p>With each additional dimension the number of possible buckets will double. As a result, for N-dimensions there will be from N to 2<sup>N</sup> buckets overlayed by the 2ɛ intervals.</p>
  
    <h4>How to construct hashes</h4>
    
  <p>Let's assume that one character of a hash is a bucket number, and that we have 10 buckets per dimension numbered from 0 to 9.</p>
  
  <p>In 2D case, in the 1st dimension we will get 1 or 2 hashes, for example: [2] or [2, 3]. In the 2nd dimension: [7] or [7, 8]. Now, to create full hashes, we combine characters of the 1st and the 2nd dimensions in the dimension order, thus getting at minimum 1 array [2, 7], and at maximum 4 arrays [2, 7], [2, 8], [3, 7], [3, 8].</p>
    
  <p>Mutually appended elements of these arrays are the basis for full hashes in 2 dimensions: "27" at minimum, and "27", "28", "37", "38" at maximum.</p>
  
  <p>Such binary trees allow to continue with additional dimensions until full hashes are ready for one N-dimensional float vector. A single hash length is N.</p>
  
  <p>In the "most economic" case there will be only 1 hash, and in the worse case there will be 2<sup>N</sup> hashes. Those 2<sup>N</sup> or less hashes will form the final hash set we need. This hash set represents our N-vector for search and comparison.</p>
  
    <h4>How to search/compare</h4>
  
  <p>Every hash is de-facto a hypercube for nearest-neighbour search/comparison. Two vectors with same hash are neighbours.</p>

  <p>For database lookup, we do not need to store the whole set of hashes per N-vector. One value from the set is enough. But, as a query, for the lookup we need all hashes from the set. It is also possible to inverse the approach and store all hashes of the vector, while using only one hash for the lookup query. Anyway, no "free lunch" here: one-to-many or many-to-one principle holds on search.</p>
  

    <h4>How the curse becomes a blessing</h4>

  
  <p>Since the hash set size may double with each additional dimension, it might seem impractical to search/compare for large N. Already for 10 dimensions we may get up to 2<sup>10</sup> = 1024 hashes in the set! The curse of dimensionality?</p>
  
  <p>To address the problem, as already mentioned for 1D case, we can choose larger bucket widths. Assuming very large bucket width and reasonably small ɛ, there will be only few cases of our value being near bucket borders, therefore only a few branches of the binary tree will be necessary. As a result we will typically get small hash sets with a few rare exceptions.</p>
  
  <p>If bucket width is large, the similarity approximation is rough, but is enough for initial grouping of similar vectors. After that, for higher precision, (slow) Euclidean distance can be used for vectors having same hash.</p>
  
  <p>To increase precision we could also add additional dimensions N+1, N+2 etc. As a result even 2 buckets per dimension may be enough. Then the curse of dimensionality becomes a blessing: number of hypercubes will grow fast to split N-space quite granularly. For example having only 4 buckets per dimension in 10-dimensional space will give us 4<sup>10</sup>> 1 million hashes. And for 8 buckets over 1 billion hashes.</p>

  <p>Another way to fight the curse of dimensionality is to split N-dimensional vector to smaller vectors, and generate hash sets for each sub-vector. Then later intersect lookup results for those sub-sets.</p>
  
  <p>The demonstrated bucket approach will work best when vector components are independent variables. Besides buckets can be distributed in a non-linear fashion, if necessary.</p>
  

  <h4>Algorithm implementation</h4>

  <p>You can view and use my code written in Go language on Github: <a href="https://github.com/vitali-fedulov/hyper">float vector hash</a>.</p>



    


  <div class = "footer">Copyright &#169; 2021 Vitali Fedulov. All rights reserved.</div>
  
</body>
</html>

